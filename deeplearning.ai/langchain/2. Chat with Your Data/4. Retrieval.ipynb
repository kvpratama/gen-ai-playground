{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e101f567",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "Retrieval is the centerpiece of our retrieval augmented generation (RAG) flow. \n",
    "\n",
    "Let's get our vectorDB from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d54cc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.environ[\"GEMINI_API_KEY\"]\n",
    "llm_model = \"gemini-2.0-flash-lite\" # \"gemma-3-27b-it\" # \n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=llm_model,\n",
    "    temperature=0.9,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "gembeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "\n",
    "# vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "cembeddings = CohereEmbeddings(model=\"embed-english-v3.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "187ec469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IdeaPad\\AppData\\Local\\Temp\\ipykernel_9848\\282814261.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = 'docs/chroma/'\n",
    "\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=gembeddings\n",
    ")\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05b8545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]\n",
    "\n",
    "smalldb = Chroma.from_texts(texts, embedding=gembeddings)\n",
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eef6774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\n",
      "The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\n"
     ]
    }
   ],
   "source": [
    "ss = smalldb.similarity_search(question, k=2)\n",
    "for s in ss:\n",
    "    print(s.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73789910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\n",
      "The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\n"
     ]
    }
   ],
   "source": [
    "ss = smalldb.max_marginal_relevance_search(question, k=2)\n",
    "for s in ss:\n",
    "    print(s.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14764949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\n",
      "A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\n",
      "A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\n",
      "A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]\n",
    "\n",
    "smalldb = Chroma.from_texts(texts, embedding=cembeddings)\n",
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\"\n",
    "\n",
    "ss = smalldb.similarity_search(question, k=2)\n",
    "for s in ss:\n",
    "    print(s.page_content)\n",
    "\n",
    "ss = smalldb.max_marginal_relevance_search(question, k=2)\n",
    "for s in ss:\n",
    "    print(s.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff392b72",
   "metadata": {},
   "source": [
    "### Addressing Diversity: Maximum marginal relevance\n",
    "\n",
    "Last class we introduced one problem: how to enforce diversity in the search results.\n",
    " \n",
    "`Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a6d274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "those homeworks will be done in either MATLAB or in Octave, which is sort of — I \n",
      "know some people c\n",
      "******************\n",
      "those homeworks will be done in either MATLAB or in Octave, which is sort of — I \n",
      "know some people c\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs_ss = vectordb.similarity_search(question,k=3)\n",
    "\n",
    "print(docs_ss[0].page_content[:100])\n",
    "print(\"******************\")\n",
    "print(docs_ss[1].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4abcac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "those homeworks will be done in either MATLAB or in Octave, which is sort of — I \n",
      "know some people c\n",
      "******************\n",
      "Okay, and using this matrix vector notation, I think, I don't know, I think we did this \n",
      "whole thing\n"
     ]
    }
   ],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)\n",
    "\n",
    "print(docs_mmr[0].page_content[:100])\n",
    "print(\"******************\")\n",
    "print(docs_mmr[1].page_content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047ce8d7",
   "metadata": {},
   "source": [
    "### Addressing Specificity: working with metadata\n",
    "\n",
    "In last lecture, we showed that a question about the third lecture can include results from other lectures as well.\n",
    "\n",
    "To address this, many vectorstores support operations on `metadata`.\n",
    "\n",
    "`metadata` provides context for each embedded chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3810fa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs/MachineLearning-Lecture03.pdf\n",
      "docs/MachineLearning-Lecture03.pdf\n",
      "docs/MachineLearning-Lecture03.pdf\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about regression in the third lecture?\"\n",
    "\n",
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\"docs/MachineLearning-Lecture03.pdf\"}\n",
    ")\n",
    "\n",
    "for d in docs:\n",
    "    print(d.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7367f0d9",
   "metadata": {},
   "source": [
    "### Addressing Specificity: working with metadata using self-query retriever\n",
    "\n",
    "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
    "\n",
    "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
    " \n",
    "1. The `query` string to use for vector search\n",
    "2. A metadata filter to pass in as well\n",
    "\n",
    "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d963eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of `docs/MachineLearning-Lecture01.pdf`, `docs/MachineLearning-Lecture02.pdf`, or `docs/MachineLearning-Lecture03.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "document_content_description = \"Lecture notes\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "question = \"what did they say about regression in the third lecture?\"\n",
    "\n",
    "docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e005297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs/MachineLearning-Lecture03.pdf 2\n",
      "docs/MachineLearning-Lecture03.pdf 14\n",
      "docs/MachineLearning-Lecture03.pdf 10\n",
      "docs/MachineLearning-Lecture03.pdf 2\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata[\"source\"], d.metadata[\"page\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837bdba9",
   "metadata": {},
   "source": [
    "### Additional tricks: compression\n",
    "\n",
    "Another approach for improving the quality of retrieved docs is compression.\n",
    "\n",
    "Information most relevant to a query may be buried in a document with a lot of irrelevant text. \n",
    "\n",
    "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
    "\n",
    "Contextual compression is meant to fix this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d0a1298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "MATLAB is I guess part of the programming language that makes it very easy to \n",
      "write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of \n",
      "learning algorithms.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "MATLAB is I guess part of the programming language that makes it very easy to \n",
      "write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of \n",
      "learning algorithms.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "And the student said, \"Oh, it was the MATLAB.\"\n",
      "So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, \n",
      "and we'll actually have a short MATLAB tutorial in one of the discussion sections for \n",
      "those of you that don't know it.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "And the student said, \"Oh, it was the MATLAB.\"\n",
      "So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, \n",
      "and we'll actually have a short MATLAB tutorial in one of the discussion sections for \n",
      "those of you that don't know it.\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n",
    "\n",
    "\n",
    "# Wrap our vectorstore\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")\n",
    "\n",
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.invoke(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c7527",
   "metadata": {},
   "source": [
    "### Combine with MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d5be3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "MATLAB is I guess part of the programming language that makes it very easy to \n",
      "write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of \n",
      "learning algorithms.\n"
     ]
    }
   ],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    ")\n",
    "\n",
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d85eb8",
   "metadata": {},
   "source": [
    "## Other types of retrieval\n",
    "\n",
    "It's worth noting that vectordb as not the only kind of tool to retrieve documents. \n",
    "\n",
    "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1dc6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load PDF\n",
    "loader = PyPDFLoader(\"docs/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n",
    "\n",
    "# Retrieve\n",
    "svm_retriever = SVMRetriever.from_texts(splits,gembeddings)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3be8d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content=\"find project partners to do your project with. And also, this is a good time to start forming \\nstudy groups, so either talk to your friends or post in the newsgroup, but we just \\nencourage you to try to start to do both of those today, okay? Form study groups, and try \\nto find two other project partners.  \\nSo thank you. I'm looking forward to teaching this class, and I'll see you in a couple of \\ndays. [End of Audio]  \\nDuration: 69 minutes\")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c1d1364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content=\"personally could, and this is an instance of maybe computers learning to do things that \\nthey were not programmed explicitly to do.  \\nHere's a more recent, a more modern, more formal definition of machine learning due to \\nTom Mitchell, who says that a well-posed learning problem is defined as follows: He \\nsays that a computer program is set to learn from an experience E with respect to some \\ntask T and some performance measure P if its performance on T as measured by P \\nimproves with experience E. Okay. So not only is it a definition, it even rhymes.  \\nSo, for example, in the case of checkers, the experience E that a program has would be \\nthe experience of playing lots of games of checkers against itself, say. The task T is the \\ntask of playing checkers, and the performance measure P will be something like the \\nfraction of games it wins against a certain set of human opponents. And by this \\ndefinition, we'll say that Arthur Samuel's checkers program has learned to play checkers, \\nokay?  \\nSo as an overview of what we're going to do in this class, this class is sort of organized \\ninto four major sections. We're gonna talk about four major topics in this class, the first \\nof which is supervised learning. So let me give you an example of that.  \\nSo suppose you collect a data set of housing prices. And one of the TAs, Dan Ramage, \\nactually collected a data set for me last week to use in the example later. But suppose that\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "docs_svm=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
