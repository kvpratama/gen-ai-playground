{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Lab 1 Summarize Dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IdeaPad\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_dataset_name = \"knkarthick/dialogsum\"\n",
    "dataset = load_dataset(hf_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'dialogue', 'summary', 'topic'])\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example  1\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Input Dialog: \n",
      "#Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Human Summary: #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example  2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Input Dialog: \n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Human Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices = [40, 200]\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dataset['test'][0].keys())\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "\n",
    "    print(dash_line)\n",
    "    print('Example ', i+1)\n",
    "    print(dash_line)\n",
    "    print('Input Dialog: ')\n",
    "    print(dataset['test'][index]['dialogue'])\n",
    "    print(dash_line)\n",
    "    print('Human Summary: ', end=\"\")\n",
    "    print(dataset['test'][index]['summary'])\n",
    "    print(dash_line)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IdeaPad\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\io\\image.py:14: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\IdeaPad\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'google/flan-t5-base'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded sentence:  tensor([[ 363,   97,   19,   34,    6, 3059,   58,    1]])\n",
      "Decoded token:  What time is it, Tom?\n"
     ]
    }
   ],
   "source": [
    "sentence = \"What time is it, Tom?\"\n",
    "\n",
    "sentece_encoded = tokenizer.encode(sentence, return_tensors='pt')\n",
    "\n",
    "sentence_decoded = tokenizer.decode(sentece_encoded[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Encoded sentence: \", sentece_encoded)\n",
    "\n",
    "print(\"Decoded token: \", sentence_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a printing helper function\n",
    "def print_output(dialogue, summary, model_output):\n",
    "    print(\"Dialoge: \")\n",
    "    print(dialogue)\n",
    "    print(dash_line)\n",
    "    print(\"Summary: \", end=\"\")\n",
    "    print(summary)\n",
    "    print(\"Model Output: \", end=\"\")\n",
    "    print(model_output)\n",
    "    print(dash_line)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialoge: \n",
      "#Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Summary: #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "Model Output: Person1: It's ten to nine.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dialoge: \n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "Model Output: #Person1#: I'm thinking of upgrading my computer.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See Model output without any prompt\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['test'][index]['dialogue']\n",
    "    summary = dataset['test'][index]['summary']\n",
    "    tokenized_dialogue = tokenizer(dialogue, return_tensors='pt')\n",
    "\n",
    "    model_output = tokenizer.decode(model.generate(tokenized_dialogue['input_ids'], max_new_tokens=50)[0], skip_special_tokens=True)\n",
    "    print_output(dialogue, summary, model_output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot Inference with an Instruction Prompt\n",
    "### See model output with prompt to summarize the given input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialoge: \n",
      "\n",
      "    Summarize the following conversation:\n",
      "    #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "    Summary: \n",
      "    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Summary: #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "Model Output: The train is about to leave.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dialoge: \n",
      "\n",
      "    Summarize the following conversation:\n",
      "    #Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "    Summary: \n",
      "    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "Model Output: #Person1#: You'd probably want to upgrade your computer. #Person2#: You could also upgrade your hardware. #Person1#: You'd probably want a faster processor, more memory and a\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Zero Shot Inference with an Instruction Prompth\n",
    "# See model output with prompt to summarize the given input\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['test'][index]['dialogue']\n",
    "    summary = dataset['test'][index]['summary']\n",
    "    # input_prompt = prompt + dialogue\n",
    "    input_prompt = f\"\"\"\n",
    "    Summarize the following conversation:\n",
    "    {dialogue}\n",
    "    Summary: \n",
    "    \"\"\"\n",
    "    tokenized_dialogue = tokenizer(input_prompt , return_tensors='pt')\n",
    "\n",
    "    model_output = tokenizer.decode(model.generate(tokenized_dialogue['input_ids'], max_new_tokens=50)[0], skip_special_tokens=True)\n",
    "    print_output(input_prompt, summary, model_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summarize Dialogue with One Shot and Few Shot Inference\n",
    "\n",
    "Build a function to generate prompt that end with a prompt that you want the model to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue: \n",
      "                        #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "                     What was going on? \n",
      "                        #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "                    Dialoge: #Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks. \n",
      " What was going on? \n"
     ]
    }
   ],
   "source": [
    "def make_prompt(list_idx, dataset, idx_to_sum):\n",
    "    output_prompt = \"\"\n",
    "    for i, index in enumerate(list_idx):\n",
    "        dialogue = dataset[index]['dialogue']\n",
    "        summary = dataset[index]['summary']\n",
    "        prompt = f\"\"\"Dialogue: \n",
    "                        {dialogue}\n",
    "                     What was going on? \n",
    "                        {summary}\n",
    "                    \"\"\"  \n",
    "        output_prompt += prompt\n",
    "\n",
    "    output_prompt += f\"Dialoge: {dataset[idx_to_sum]['dialogue']} \\n What was going on? \" \n",
    "    return output_prompt\n",
    "\n",
    "print(make_prompt([40], dataset['test'], 200))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 One Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialoge: \n",
      "Dialogue: \n",
      "                        #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "                     What was going on? \n",
      "                        #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "                    Dialoge: #Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks. \n",
      " What was going on? \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "Model Output: #Person1 wants to upgrade his computer. #Person2 wants to add a painting program to his software. #Person1 wants to add a CD-ROM drive.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_prompt = make_prompt([40], dataset['test'], 200)\n",
    "tokenized_input = tokenizer(input_prompt, return_tensors='pt')\n",
    "model_output = tokenizer.decode(model.generate(tokenized_input['input_ids'], max_new_tokens=50)[0], skip_special_tokens=True)\n",
    "\n",
    "print_output(input_prompt, dataset['test'][200]['summary'], model_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Few Shot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialoge: \n",
      "Dialogue: \n",
      "                        #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "                     What was going on? \n",
      "                        #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "                    Dialogue: \n",
      "                        #Person1#: May, do you mind helping me prepare for the picnic?\n",
      "#Person2#: Sure. Have you checked the weather report?\n",
      "#Person1#: Yes. It says it will be sunny all day. No sign of rain at all. This is your father's favorite sausage. Sandwiches for you and Daniel.\n",
      "#Person2#: No, thanks Mom. I'd like some toast and chicken wings.\n",
      "#Person1#: Okay. Please take some fruit salad and crackers for me.\n",
      "#Person2#: Done. Oh, don't forget to take napkins disposable plates, cups and picnic blanket.\n",
      "#Person1#: All set. May, can you help me take all these things to the living room?\n",
      "#Person2#: Yes, madam.\n",
      "#Person1#: Ask Daniel to give you a hand?\n",
      "#Person2#: No, mom, I can manage it by myself. His help just causes more trouble.\n",
      "                     What was going on? \n",
      "                        Mom asks May to help to prepare for the picnic and May agrees.\n",
      "                    Dialogue: \n",
      "                        #Person1#: Hello, I bought the pendant in your shop, just before. \n",
      "#Person2#: Yes. Thank you very much. \n",
      "#Person1#: Now I come back to the hotel and try to show it to my friend, the pendant is broken, I'm afraid. \n",
      "#Person2#: Oh, is it? \n",
      "#Person1#: Would you change it to a new one? \n",
      "#Person2#: Yes, certainly. You have the receipt? \n",
      "#Person1#: Yes, I do. \n",
      "#Person2#: Then would you kindly come to our shop with the receipt by 10 o'clock? We will replace it. \n",
      "#Person1#: Thank you so much. \n",
      "                     What was going on? \n",
      "                        #Person1# wants to change the broken pendant in #Person2#'s shop.\n",
      "                    Dialoge: #Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks. \n",
      " What was going on? \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "Model Output: #Person1 wants to upgrade his computer. #Person2 wants to add a painting program to his software. #Person1 wants to upgrade his hardware.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_prompt = make_prompt([40, 80, 120], dataset['test'], 200)\n",
    "tokenized_input = tokenizer(input_prompt, return_tensors='pt')\n",
    "model_output = tokenizer.decode(model.generate(tokenized_input['input_ids'], max_new_tokens=50)[0], skip_special_tokens=True)\n",
    "\n",
    "print_output(input_prompt, dataset['test'][200]['summary'], model_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generative Configuration Parameters for Inference\n",
    "\n",
    "Change the configuration parameters of the `generate()` method to see different output from the LLM. A full list of available parameters can be found in the [Hugging Face Generation documentation](https://huggingface.co/docs/transformers/en/main_classes/text_generation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Human Summary:  #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "\n",
      "Temperature:  0.1\n",
      "1 #Person1 wants to upgrade his computer. #Person2 wants to add a painting program to his software. #Person1 wants to upgrade his hardware.\n",
      "2 #Person1 wants to upgrade his computer.\n",
      "3 #Person1 wants to upgrade his computer and hardware.\n",
      "4 #Person1 wants to upgrade his computer.\n",
      "5 #Person1 wants to upgrade his computer.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Temperature:  1.0\n",
      "1 At this moment, Person1 is choosing a new computer system to upgrade.\n",
      "2 People can buy a new computer through an internet browser or mobile phone, as most software projects are coming out on Cds today.\n",
      "3 #Replacement is a program that will make user's life easier.\n",
      "4 #Person2 recommends some options about upgrading a computer.\n",
      "5 At the moment, Person1 has to decide which software to choose from.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Temperature:  2.0\n",
      "1 Most recent online advertisements have taken shape with this program.\n",
      "2 All for you: #parson's advice: do a lot for the future now and put any essential software upgrades into. Most applications come open on CD copies. Don't bother with the DVD drive, as more and the system speed\n",
      "3 The people will consider all the above. #If you have tried for an extended backup I won't mention it at some point. #Right in.\n",
      "4 When doing computer and systems updates it would be best to get some more applications (options available for windows. Software doesn't have these things at this moment at some software stores, though the majority of the latest software products comes through on APD\n",
      "5 Ask People the following questions as: Should someone go with his or her PC systems on the website or with their computer on his computer. Will something not conceivably change like hard discs could go at some untrue moment when he or\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Temperature:  3.0\n",
      "1 Person2 finds upgrade with software easier to achieve.\n",
      "2 According to Mrs McAnair, changing computers could result for your application processing errors and slow graphics as time go By; you need all kinds technology while computer software could update faster but doesn;,. Have any suggestions yet you have.,\n",
      "3 Persone is thinking he might install all of upgrading it on their laptop when his business ends recently. For other technology enhancement: #person1 advice will involve at #1 adding painting program *+ 2 or even printing the first word while #2 consider software\n",
      "4 Most commie programs should be more compatible with CD-Ms... They recommend getting infrared printer so that there can get outflutter from light uplight or color blur and also do it at ease while doing manual programming jobs.\n",
      "5 No physical memory in general still requires a hardware upgrade at current rate, but an SSD computer with DCI cards could replace the ones required when able-, due a few minor details in a document (or other info by person.\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "temperature=[0.1, 1.0, 2.0, 3.0]\n",
    "# generation_config = GenerationConfig(max_new_tokens=50)\n",
    "# generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=1.0)\n",
    "\n",
    "input_prompt = make_prompt([40, 80, 120], dataset['test'], 200)\n",
    "tokenized_input = tokenizer(input_prompt, return_tensors='pt')\n",
    "print(\"Baseline Human Summary: \", dataset['test'][200]['summary'])\n",
    "print()\n",
    "\n",
    "for temp in temperature:\n",
    "    print(\"Temperature: \", temp)\n",
    "    generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=temp)\n",
    "    for i in range(5):\n",
    "        model_output = tokenizer.decode(model.generate(tokenized_input['input_ids'], generation_config=generation_config)[0], skip_special_tokens=True)\n",
    "        print(i+1, model_output)\n",
    "    print(dash_line)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
