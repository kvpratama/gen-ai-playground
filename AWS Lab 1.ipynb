{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IdeaPad\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\IdeaPad\\.cache\\huggingface\\hub\\datasets--knkarthick--dialogsum. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 12460/12460 [00:00<00:00, 50514.39 examples/s]\n",
      "Generating validation split: 100%|██████████| 500/500 [00:00<00:00, 32716.88 examples/s]\n",
      "Generating test split: 100%|██████████| 1500/1500 [00:00<00:00, 52566.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "hf_dataset_name = \"knkarthick/dialogsum\"\n",
    "dataset = load_dataset(hf_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'dialogue', 'summary', 'topic'])\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example  1\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Input Dialog: \n",
      "#Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Human Summary: #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Example  2\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Input Dialog: \n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Human Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_indices = [40, 200]\n",
    "\n",
    "dash_line = '-'.join('' for x in range(100))\n",
    "print(dataset['test'][0].keys())\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "\n",
    "    print(dash_line)\n",
    "    print('Example ', i+1)\n",
    "    print(dash_line)\n",
    "    print('Input Dialog: ')\n",
    "    print(dataset['test'][index]['dialogue'])\n",
    "    print(dash_line)\n",
    "    print('Human Summary: ', end=\"\")\n",
    "    print(dataset['test'][index]['summary'])\n",
    "    print(dash_line)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'google/flan-t5-base'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded sentence:  tensor([[ 363,   97,   19,   34,    6, 3059,   58,    1]])\n",
      "Decoded token:  What time is it, Tom?\n"
     ]
    }
   ],
   "source": [
    "sentence = \"What time is it, Tom?\"\n",
    "\n",
    "sentece_encoded = tokenizer.encode(sentence, return_tensors='pt')\n",
    "\n",
    "sentence_decoded = tokenizer.decode(sentece_encoded[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Encoded sentence: \", sentece_encoded)\n",
    "\n",
    "print(\"Decoded token: \", sentence_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a printing helper function\n",
    "def print_output(dialogue, summary, model_output):\n",
    "    print(\"Dialoge: \")\n",
    "    print(dialogue)\n",
    "    print(dash_line)\n",
    "    print(\"Summary: \", end=\"\")\n",
    "    print(summary)\n",
    "    print(\"Model Output: \", end=\"\")\n",
    "    print(model_output)\n",
    "    print(dash_line)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialoge: \n",
      "#Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Summary: #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "Model Output: Person1: It's ten to nine.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dialoge: \n",
      "#Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "Model Output: #Person1#: I'm thinking of upgrading my computer.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See Model output without any prompt\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['test'][index]['dialogue']\n",
    "    summary = dataset['test'][index]['summary']\n",
    "    tokenized_dialogue = tokenizer(dialogue, return_tensors='pt')\n",
    "\n",
    "    model_output = tokenizer.decode(model.generate(tokenized_dialogue['input_ids'], max_new_tokens=50)[0], skip_special_tokens=True)\n",
    "    print_output(dialogue, summary, model_output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialoge: \n",
      "\n",
      "    Summarize the following conversation:\n",
      "    #Person1#: What time is it, Tom?\n",
      "#Person2#: Just a minute. It's ten to nine by my watch.\n",
      "#Person1#: Is it? I had no idea it was so late. I must be off now.\n",
      "#Person2#: What's the hurry?\n",
      "#Person1#: I must catch the nine-thirty train.\n",
      "#Person2#: You've plenty of time yet. The railway station is very close. It won't take more than twenty minutes to get there.\n",
      "    Summary: \n",
      "    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Summary: #Person1# is in a hurry to catch a train. Tom tells #Person1# there is plenty of time.\n",
      "Model Output: The train is about to leave.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Dialoge: \n",
      "\n",
      "    Summarize the following conversation:\n",
      "    #Person1#: Have you considered upgrading your system?\n",
      "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
      "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
      "#Person2#: That would be a definite bonus.\n",
      "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
      "#Person2#: How can we do that?\n",
      "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
      "#Person2#: No.\n",
      "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
      "#Person2#: That sounds great. Thanks.\n",
      "    Summary: \n",
      "    \n",
      "---------------------------------------------------------------------------------------------------\n",
      "Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
      "Model Output: #Person1#: You'd probably want to upgrade your computer. #Person2#: You could also upgrade your hardware. #Person1#: You'd probably want a faster processor, more memory and a\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See model output with prompt to summarize the given input\n",
    "\n",
    "for i, index in enumerate(example_indices):\n",
    "    dialogue = dataset['test'][index]['dialogue']\n",
    "    summary = dataset['test'][index]['summary']\n",
    "    # input_prompt = prompt + dialogue\n",
    "    input_prompt = f\"\"\"\n",
    "    Summarize the following conversation:\n",
    "    {dialogue}\n",
    "    Summary: \n",
    "    \"\"\"\n",
    "    tokenized_dialogue = tokenizer(input_prompt , return_tensors='pt')\n",
    "\n",
    "    model_output = tokenizer.decode(model.generate(tokenized_dialogue['input_ids'], max_new_tokens=50)[0], skip_special_tokens=True)\n",
    "    print_output(input_prompt, summary, model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue: \n",
      "                        #Person1#: Where are you going for your trip?\n",
      "#Person2#: I think Hebei is a good place.\n",
      "#Person1#: But I heard the north of China are experiencing severe sandstorms!\n",
      "#Person2#: Really?\n",
      "#Person1#: Yes, it's said that Hebes was experiencing six degree strong winds.\n",
      "#Person2#: How do these storms affect the people who live in these areas?\n",
      "#Person1#: The report said the number of people with respiratory tract infections tended to rise after sandstorms. The sand gets into people's noses and throats and creates irritation.\n",
      "#Person2#: It sounds that sandstorms are trouble for everybody!\n",
      "#Person1#: You are quite right.\n",
      "                     Summary: \n",
      "                        #Person2# plans to have a trip in Hebei but #Person1# says there are sandstorms in there.\n",
      "                    Dialogue: \n",
      "                        #Person1#: Where are you going for your trip?\n",
      "#Person2#: I think Hebei is a good place.\n",
      "#Person1#: But I heard the north of China are experiencing severe sandstorms!\n",
      "#Person2#: Really?\n",
      "#Person1#: Yes, it's said that Hebes was experiencing six degree strong winds.\n",
      "#Person2#: How do these storms affect the people who live in these areas?\n",
      "#Person1#: The report said the number of people with respiratory tract infections tended to rise after sandstorms. The sand gets into people's noses and throats and creates irritation.\n",
      "#Person2#: It sounds that sandstorms are trouble for everybody!\n",
      "#Person1#: You are quite right.\n",
      "                     Summary: \n",
      "                        #Person2# wants to travel to Hebei but #Person1# informs #Person2# of terrible sandstorms there.\n",
      "                    Dialoge: #Person1#: Where are you going for your trip?\n",
      "#Person2#: I think Hebei is a good place.\n",
      "#Person1#: But I heard the north of China are experiencing severe sandstorms!\n",
      "#Person2#: Really?\n",
      "#Person1#: Yes, it's said that Hebes was experiencing six degree strong winds.\n",
      "#Person2#: How do these storms affect the people who live in these areas?\n",
      "#Person1#: The report said the number of people with respiratory tract infections tended to rise after sandstorms. The sand gets into people's noses and throats and creates irritation.\n",
      "#Person2#: It sounds that sandstorms are trouble for everybody!\n",
      "#Person1#: You are quite right. \n",
      " Summary: \n"
     ]
    }
   ],
   "source": [
    "def make_prompt(list_idx, dataset, idx_to_sum):\n",
    "    output_prompt = \"\"\n",
    "    for i, index in enumerate(list_idx):\n",
    "        dialogue = dataset[index]['dialogue']\n",
    "        summary = dataset[index]['summary']\n",
    "        prompt = f\"\"\"Dialogue: \n",
    "                        {dialogue}\n",
    "                     Summary: \n",
    "                        {summary}\n",
    "                    \"\"\"  \n",
    "        output_prompt += prompt\n",
    "\n",
    "    output_prompt += f\"Dialoge: {dataset[idx_to_sum]['dialogue']} \\n Summary: \" \n",
    "    return output_prompt\n",
    "\n",
    "print(make_prompt([30, 32], dataset['test'], 31))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue: \n",
      "                        #Person1#: What's wrong with you? Why are you scratching so much?\n",
      "#Person2#: I feel itchy! I can't stand it anymore! I think I may be coming down with something. I feel lightheaded and weak.\n",
      "#Person1#: Let me have a look. Whoa! Get away from me!\n",
      "#Person2#: What's wrong?\n",
      "#Person1#: I think you have chicken pox! You are contagious! Get away! Don't breathe on me!\n",
      "#Person2#: Maybe it's just a rash or an allergy! We can't be sure until I see a doctor.\n",
      "#Person1#: Well in the meantime you are a biohazard! I didn't get it when I was a kid and I've heard that you can even die if you get it as an adult!\n",
      "#Person2#: Are you serious? You always blow things out of proportion. In any case, I think I'll go take an oatmeal bath.\n",
      "                     Summary: \n",
      "                        #Person1# thinks #Person2# has chicken pox and warns #Person2# about the possible hazards but #Person2# thinks it will be fine.\n",
      "                    Dialoge: #Person1#: Good coming. What can I do for you?\n",
      "#Person2#: I'm in Room 309. I'm checking out today. Can I have my bill now?\n",
      "#Person1#: Certainly. Please wait a moment. Here you are.\n",
      "#Person2#: Thanks. Wait... What's this? The 30 dollar for?\n",
      "#Person1#: Excuse me... The charge for your laundry service on Nov. 20th.\n",
      "#Person2#: But I did't take any laundry service during my stay here. I think you have added someone else's.\n",
      "#Person1#: Ummmm...Sorry, would you mind waiting a moment? We check it with the department concerned.\n",
      "#Person2#: No. As long as we get this straightened out.\n",
      "#Person1#: I'm very sorry. There has been a mistake. We'll correct the bill. Please take a look.\n",
      "#Person2#: Okay, here you are.\n",
      "#Person1#: Goodbye. \n",
      " Summary: \n",
      "The laundry charge for Nov. 20th is 30 dollars.\n"
     ]
    }
   ],
   "source": [
    "input_prompt = make_prompt([20], dataset['test'], 21)\n",
    "tokenized_input = tokenizer(input_prompt, return_tensors='pt')\n",
    "model_output = tokenizer.decode(model.generate(tokenized_input['input_ids'], max_new_tokens=50)[0], skip_special_tokens=True)\n",
    "\n",
    "print(input_prompt)\n",
    "print(model_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
