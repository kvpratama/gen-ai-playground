{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine-tuning for classification with LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Labels</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Labels                                               Text\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568    ham               Will ü b going to esplanade fr home?\n",
       "5569    ham  Pity, * was in mood for that. So...any other s...\n",
       "5570    ham  The guy did some bitching but I acted like i'd...\n",
       "5571    ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Labels\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Labels\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    num_spam = df[df[\"Labels\"] == \"spam\"].shape[0]\n",
    "    ham_subset = df[df[\"Labels\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Labels\"] == \"spam\"]])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Labels\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labels\n",
       "0    747\n",
       "1    747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"Labels\"] = balanced_df[\"Labels\"].map({\"spam\": 1, \"ham\": 0})\n",
    "balanced_df[\"Labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end= train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Creating data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        self.encoded_text = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            self.encoded_text = [encoded_text[:self.max_length] for encoded_text in self.encoded_text]\n",
    "\n",
    "        self.encoded_text = [encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) for encoded_text in self.encoded_text]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_text[index]\n",
    "        label = self.data.iloc[index][\"Labels\"]\n",
    "        return (torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_text:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_maxlength = model.pos_emb.weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimension: torch.Size([8, 120])\n",
      "Label batch dimension: torch.Size([8])\n",
      "Input batch dimension: torch.Size([5, 120])\n",
      "Label batch dimension: torch.Size([5])\n",
      "Input batch dimension: torch.Size([4, 120])\n",
      "Label batch dimension: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimension:\", input_batch.shape)\n",
    "print(\"Label batch dimension:\", target_batch.shape)\n",
    "\n",
    "for input_batch, target_batch in val_loader:\n",
    "    pass\n",
    "print(\"Input batch dimension:\", input_batch.shape)\n",
    "print(\"Label batch dimension:\", target_batch.shape)\n",
    "\n",
    "for input_batch, target_batch in test_loader:\n",
    "    pass\n",
    "print(\"Input batch dimension:\", input_batch.shape)\n",
    "print(\"Label batch dimension:\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Initializing a model with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True,\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output, it’s apparent that the model is struggling to follow instructions.\n",
    "This result is expected, as it has only undergone pretraining and lacks instruction\n",
    "fine-tuning. So, let’s prepare the model for classification fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)\n",
    "device = torch.device(\"xpu\" if torch.xpu.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Calculating the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]\n",
    "            \n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += ((predicted_labels == target_batch).sum().item())\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Val accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = \"xpu\" if torch.xpu.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_acc = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_acc = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_acc = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_acc*100:.2f}%\")\n",
    "print(f\"Val accuracy: {val_acc*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.4 Parameter-efficient fine-tuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(linear.in_features, linear.out_features, rank, alpha)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else:\n",
    "            replace_linear_with_lora(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable params before: 124,441,346\n",
      "Total trainable params after: 0\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable params before: {total_params:,}\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable params after: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA params: 2,666,528\n"
     ]
    }
   ],
   "source": [
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable LoRA params: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Val accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "train_acc = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_acc = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_acc = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_acc*100:.2f}%\")\n",
    "print(f\"Val accuracy: {val_acc*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    logits = model(input_batch)[:, -1, :]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Val loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Val loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7 Fine-tuning the model on supervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss.cpu())\n",
    "                val_losses.append(val_loss.cpu())\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}) : \"\n",
    "                      f\"Train loss {train_loss:.3f}, \" \n",
    "                      f\"Eval Loss: {val_loss:.3f}\"\n",
    "                      )\n",
    "                \n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\n",
    "        print(f\"Train accuracy: {train_accuracy*100:.2f} % | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f} %\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "    \n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    \n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000) : Train loss 3.820, Eval Loss: 3.462\n",
      "Ep 1 (Step 000050) : Train loss 0.396, Eval Loss: 0.364\n",
      "Ep 1 (Step 000100) : Train loss 0.111, Eval Loss: 0.229\n",
      "Train accuracy: 97.50 % | Validation accuracy: 95.00 %\n",
      "Ep 2 (Step 000150) : Train loss 0.135, Eval Loss: 0.073\n",
      "Ep 2 (Step 000200) : Train loss 0.007, Eval Loss: 0.053\n",
      "Ep 2 (Step 000250) : Train loss 0.022, Eval Loss: 0.180\n",
      "Train accuracy: 97.50 % | Validation accuracy: 97.50 %\n",
      "Ep 3 (Step 000300) : Train loss 0.095, Eval Loss: 0.067\n",
      "Ep 3 (Step 000350) : Train loss 0.030, Eval Loss: 0.157\n",
      "Train accuracy: 100.00 % | Validation accuracy: 97.50 %\n",
      "Ep 4 (Step 000400) : Train loss 0.021, Eval Loss: 0.073\n",
      "Ep 4 (Step 000450) : Train loss 0.003, Eval Loss: 0.132\n",
      "Ep 4 (Step 000500) : Train loss 0.026, Eval Loss: 0.163\n",
      "Train accuracy: 100.00 % | Validation accuracy: 95.00 %\n",
      "Ep 5 (Step 000550) : Train loss 0.002, Eval Loss: 0.355\n",
      "Ep 5 (Step 000600) : Train loss 0.006, Eval Loss: 0.013\n",
      "Train accuracy: 100.00 % | Validation accuracy: 92.50 %\n",
      "Training completed in 6.16 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq=50, eval_iter=5)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-loraplot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 100.00%\n",
      "Val accuracy: 95.30%\n",
      "Test accuracy: 97.33%\n"
     ]
    }
   ],
   "source": [
    "train_acc = calc_accuracy_loader(train_loader, model, device)\n",
    "val_acc = calc_accuracy_loader(val_loader, model, device)\n",
    "test_acc = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_acc*100:.2f}%\")\n",
    "print(f\"Val accuracy: {val_acc*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.8 Using the LLM as a spam classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]\n",
    "    \n",
    "    predicted_labels = torch.argmax(logits, dim=-1).item()\n",
    "    return \"spam\" if predicted_labels == 1 else \"not spam\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier_lora.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier_lora.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
